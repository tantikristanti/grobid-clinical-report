grobidHome: "../grobid-home/"

# path relative to the corpus and template path
dataPath: "resources/dataset/"

models:
  # we configure here how each sequence labeling model should be implemented
  # for feature-engineered CRF, use "wapiti" and possible training parameters are window, epsilon and nbMaxIterations
  # for Deep Learning, use "delft" and select the target DL architecture (see DeLFT library), the training
  # parameters then depends on this selected DL architecture

  - name: "medical-report-segmenter"
    # at this time, must always be CRF wapiti, the input sequence size is too large for a Deep Learning implementation
    engine: "wapiti"
    wapiti:
      # wapiti training parameters, they will be used at training time only
      epsilon: 0.0000001
      window: 50
      nbMaxIterations: 2000

  - name: "full-medical-text"
    # at this time, must always be CRF wapiti, the input sequence size is too large for a Deep Learning implementation
    engine: "wapiti"
    wapiti:
      # wapiti training parameters, they will be used at training time only
      epsilon: 0.0001
      window: 20
      nbMaxIterations: 1500

  - name: "header-medical-report"
    engine: "wapiti"
    wapiti:
      # wapiti training parameters, they will be used at training time only
      epsilon: 0.000001
      window: 30
      nbMaxIterations: 1500

  - name: "left-note-medical-report"
    engine: "wapiti"
    wapiti:
      # wapiti training parameters, they will be used at training time only
      epsilon: 0.000001
      window: 30
      nbMaxIterations: 1500

  - name: "organization"
    engine: "wapiti"
    wapiti:
      # wapiti training parameters, they will be used at training time only
      epsilon: 0.000001
      window: 30
      nbMaxIterations: 1500
    delft:
      # deep learning parameters
      architecture: "BidLSTM_CRF_FEATURES"

  - name: "fr-medical-ner"
    engine: "wapiti"
    wapiti:
      # wapiti training parameters, they will be used at training time only
      epsilon: 0.000001
      window: 20
      nbMaxIterations: 1000
    delft:
      # deep learning parameters
      architecture: "BidLSTM_CRF_FEATURES"
  - name: "fr-medical-ner-quaero"
    engine: "wapiti"
    wapiti:
      # wapiti training parameters, they will be used at training time only
      epsilon: 0.000001
      window: 20
      nbMaxIterations: 1000
    delft:
      # deep learning parameters
      architecture: "BidLSTM_CRF_FEATURES"

  - name: "ner"
    # at this time, must always be CRF wapiti, the input sequence size is too large for a Deep Learning implementation
    engine: "wapiti"
    wapiti:
      # wapiti training parameters, they will be used at training time only
      epsilon: 0.000001
      window: 50
      nbMaxIterations: 1000
    delft:
      # deep learning parameters
      architecture: "BidLSTM_CRF_FEATURES"

  - name: "nerfr"
    # at this time, must always be CRF wapiti, the input sequence size is too large for a Deep Learning implementation
    engine: "wapiti"
    wapiti:
      # wapiti training parameters, they will be used at training time only
      epsilon: 0.000001
      window: 20
      nbMaxIterations: 1000
    delft:
      # deep learning parameters
      architecture: "BidLSTM_CRF_FEATURES"

  - name: "dateline"
    # at this time, must always be CRF wapiti, the input sequence size is too large for a Deep Learning implementation
    engine: "wapiti"
    #engine: "delft"
    wapiti:
      # wapiti training parameters, they will be used at training time only
      epsilon: 0.000001
      window: 20
      nbMaxIterations: 1000
    delft:
      # deep learning parameters
      architecture: "BidLSTM_CRF_FEATURES"

  - name: "medic"
    # at this time, must always be CRF wapiti, the input sequence size is too large for a Deep Learning implementation
    engine: "wapiti"
    #engine: "delft"
    wapiti:
      # wapiti training parameters, they will be used at training time only
      epsilon: 0.000001
      window: 20
      nbMaxIterations: 1000
    delft:
      # deep learning parameters
      architecture: "BidLSTM_CRF_FEATURES"

  - name: "patient"
    # at this time, must always be CRF wapiti, the input sequence size is too large for a Deep Learning implementation
    engine: "wapiti"
    #engine: "delft"
    wapiti:
      # wapiti training parameters, they will be used at training time only
      epsilon: 0.000001
      window: 20
      nbMaxIterations: 1000
    delft:
      # deep learning parameters
      architecture: "BidLSTM_CRF_FEATURES"

  - name: "name-person-medical"
    # at this time, must always be CRF wapiti, the input sequence size is too large for a Deep Learning implementation
    engine: "wapiti"
    #engine: "delft"
    wapiti:
      # wapiti training parameters, they will be used at training time only
      epsilon: 0.000001
      window: 20
      nbMaxIterations: 1000
    delft:
      # deep learning parameters
      architecture: "BidLSTM_CRF_FEATURES"

  - name: "address"
      # at this time, must always be CRF wapiti, the input sequence size is too large for a Deep Learning implementation
      engine: "wapiti"
      #engine: "delft"
      wapiti:
        # wapiti training parameters, they will be used at training time only
        epsilon: 0.000001
        window: 20
        nbMaxIterations: 1000
      delft:
        # deep learning parameters
        architecture: "BidLSTM_CRF_FEATURES"

  # for **service only**: how to load the models,
  # false -> models are loaded when needed (default), avoiding putting in memory useless models but slow down significantly the service at first call
  # true -> all the models are loaded into memory at the server startup, slow the start of the services and models
#  modelPreload: false
#
#server:
#  type: custom
#  applicationConnectors:
#    - type: http
#      port: 8090
#  adminConnectors:
#    - type: http
#      port: 8091
#  registerDefaultExceptionMappers: false
#  maxThreads: 128
#  maxQueuedRequests: 2048
#  acceptQueueSize: 2048
#
#logging:
#  level: INFO
#  loggers:
#    org.apache.pdfbox.pdmodel.font.PDSimpleFont: "OFF"
#  appenders:
#    - type: console
#      threshold: ALL
#      timeZone: UTC
#    - type: file
#      currentLogFilename: logs/grobid-medical-report.log
#      threshold: ALL
#      archive: true
#      archivedLogFilenamePattern: logs/grobid-medical-report-%d.log
#      archivedFileCount: 5
#      timeZone: UTC
